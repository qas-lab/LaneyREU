{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e9f7b648-6c48-419d-97d2-04f05de5919b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 20:01:17.840718: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-06-26 20:01:19.555747: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as t\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "6af2ca6f-2eb7-40c2-94d9-5976c4b5f20b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['XLA_FLAGS'] = '--xla_gpu_cuda_data_dir=/usr/local/cuda-12.3'\n",
    "#is supposed to make Sequential model work"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3eb2fde-4b42-467f-b9e8-2a7a4fd629e8",
   "metadata": {},
   "source": [
    "# Unzipping csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1fe746d5-6a96-4f6c-b462-0ec764e7112f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "uploaded_zip = '/home/claney/EclipsePlatform/eclipse_platform.zip'\n",
    "extract_dir = '/home/claney/extracted'\n",
    "if not os.path.exists(extract_dir):\n",
    "    os.makedirs(extract_dir)\n",
    "with zipfile.ZipFile(uploaded_zip, 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "\n",
    "csv_file = os.path.join(extract_dir, 'eclipse_platform.csv')\n",
    "full_df = pd.read_csv(csv_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a28c55d-9cda-4791-8922-7b2cf8a13b7e",
   "metadata": {},
   "source": [
    "# Spliting testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "90e8add3-f7b6-417c-9fc9-5a5d5bf833fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "length=len(full_df)\n",
    "split_index=int(.8*length)\n",
    "df=full_df.iloc[:split_index] #df=training set"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "985aa1a2-48b2-4306-ad22-bb1d1cf12902",
   "metadata": {},
   "source": [
    "# Fill NAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13cb216c-3171-45e6-8092-9d699faa65fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df.fillna(0,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99f7d3ca-8090-404d-99dc-de47cd0ee013",
   "metadata": {},
   "source": [
    "# Creating full_text_data column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ef3189bf-5817-4b94-afd8-791d2a1c9581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        - Setup a project that contains a *.gif resour...\n",
      "1        Opening repository resource always open the de...\n",
      "2        KM (10/2/2001 5:55:18 PM); \\tThis PR about the...\n",
      "3        - become synchronized with some project in a r...\n",
      "4        For getting/setting the managed state of a res...\n",
      "                               ...                        \n",
      "68119    Build ID: 3.3 (I am not sure what You mean by ...\n",
      "68120    There are several NPEs within the UI session t...\n",
      "68121    I20080501-0100; ; Now that were using the coll...\n",
      "68122    Created attachment 98318; screenshot; ; I20080...\n",
      "68123    Build ID: M20080221-1800; ; Steps To Reproduce...\n",
      "Name: full_text_data, Length: 68124, dtype: object\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173824/3345744263.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['full_text_data']=df['Description']+df['Title']\n",
      "/tmp/ipykernel_173824/3345744263.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['full_text_data']=df['full_text_data'].fillna('')\n"
     ]
    }
   ],
   "source": [
    "#creating freeform textual data column\n",
    "df['full_text_data']=df['Description']+df['Title']\n",
    "print(df['full_text_data'])\n",
    "df['full_text_data']=df['full_text_data'].fillna('')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67174493-d357-455b-8aab-f2d1db2d8a02",
   "metadata": {},
   "source": [
    "# Creating isDuplicate column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d3adf16e-5beb-4d8f-954c-0d45b87e36f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        0\n",
      "1        0\n",
      "2        0\n",
      "3        0\n",
      "4        0\n",
      "        ..\n",
      "68119    0\n",
      "68120    0\n",
      "68121    0\n",
      "68122    0\n",
      "68123    0\n",
      "Name: isDuplicate, Length: 68124, dtype: int64\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_173824/1537637410.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['isDuplicate'] = df['Duplicated_issue'].apply(lambda x: is_duplicate(x))\n"
     ]
    }
   ],
   "source": [
    "def is_duplicate(val):\n",
    "    return 1 if val !=0.0 else 0\n",
    "df['isDuplicate'] = df['Duplicated_issue'].apply(lambda x: is_duplicate(x))\n",
    "\n",
    "print(df['isDuplicate'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4582ba2-ffb1-4672-bc7b-952be65aec78",
   "metadata": {},
   "source": [
    "# Splitting training into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "23facb20-f704-4763-9d6a-5cdf28f5f29b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "3580be44-9337-4e1e-8476-0cbf18d186db",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['Description']  # Input features\n",
    "y = df['isDuplicate']       # Target variable\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64022b04-a657-4454-a7cf-90f124bb82cc",
   "metadata": {},
   "source": [
    "# GPU setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38391e6-bd62-4e98-b747-40cdbc4c738e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for CUDA availability\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available. Number of GPUs:\", torch.cuda.device_count())\n",
    "    print(\"CUDA device name:\", torch.cuda.get_device_name(4))\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "torch.cuda.set_device(torch.device(\"cuda:4\"))\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bd6aef-9dad-4dbc-bf51-08c4f3f853d3",
   "metadata": {},
   "source": [
    "## MLP neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "34f479e3-3143-4e3f-99fb-ee52e1bb31c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7112519a-1335-47e3-a1d3-fcb9a67d804b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.7413540015266279\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Vectorize the text data\n",
    "vectorizer = TfidfVectorizer(max_features=1000)\n",
    "X_train_vec = vectorizer.fit_transform(X_train)\n",
    "X_test_vec = vectorizer.transform(X_test)\n",
    "\n",
    "# neural net\n",
    "model1 = MLPClassifier(hidden_layer_sizes=(64, 32), activation='relu', max_iter=1000)\n",
    "model1.to(device)\n",
    "model1.fit(X_train_vec, y_train)\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = model1.predict(X_test_vec)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Test Accuracy:\", accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cd0340-3d88-4849-9faa-25c311b58138",
   "metadata": {},
   "source": [
    "# Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f91ca2b2-cdd5-4e0b-bb2f-f14030e78068",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tensorflow-gpu\n",
      "  Downloading tensorflow-gpu-2.12.0.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25lerror\n",
      "  \u001b[1;31merror\u001b[0m: \u001b[1msubprocess-exited-with-error\u001b[0m\n",
      "  \n",
      "  \u001b[31m×\u001b[0m \u001b[32mpython setup.py egg_info\u001b[0m did not run successfully.\n",
      "  \u001b[31m│\u001b[0m exit code: \u001b[1;36m1\u001b[0m\n",
      "  \u001b[31m╰─>\u001b[0m \u001b[31m[44 lines of output]\u001b[0m\n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/setuptools/_vendor/packaging/requirements.py\", line 35, in __init__\n",
      "  \u001b[31m   \u001b[0m     parsed = _parse_requirement(requirement_string)\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/setuptools/_vendor/packaging/_parser.py\", line 64, in parse_requirement\n",
      "  \u001b[31m   \u001b[0m     return _parse_requirement(Tokenizer(source, rules=DEFAULT_RULES))\n",
      "  \u001b[31m   \u001b[0m            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/setuptools/_vendor/packaging/_parser.py\", line 82, in _parse_requirement\n",
      "  \u001b[31m   \u001b[0m     url, specifier, marker = _parse_requirement_details(tokenizer)\n",
      "  \u001b[31m   \u001b[0m                              ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/setuptools/_vendor/packaging/_parser.py\", line 126, in _parse_requirement_details\n",
      "  \u001b[31m   \u001b[0m     marker = _parse_requirement_marker(\n",
      "  \u001b[31m   \u001b[0m              ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/setuptools/_vendor/packaging/_parser.py\", line 147, in _parse_requirement_marker\n",
      "  \u001b[31m   \u001b[0m     tokenizer.raise_syntax_error(\n",
      "  \u001b[31m   \u001b[0m   File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/setuptools/_vendor/packaging/_tokenizer.py\", line 165, in raise_syntax_error\n",
      "  \u001b[31m   \u001b[0m     raise ParserSyntaxError(\n",
      "  \u001b[31m   \u001b[0m setuptools.extern.packaging._tokenizer.ParserSyntaxError: Expected end or semicolon (after name and no valid version specifier)\n",
      "  \u001b[31m   \u001b[0m     python_version>\"3.7\"\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m The above exception was the direct cause of the following exception:\n",
      "  \u001b[31m   \u001b[0m \n",
      "  \u001b[31m   \u001b[0m Traceback (most recent call last):\n",
      "  \u001b[31m   \u001b[0m   File \"<string>\", line 2, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"<pip-setuptools-caller>\", line 34, in <module>\n",
      "  \u001b[31m   \u001b[0m   File \"/tmp/pip-install-kdwyowk3/tensorflow-gpu_a2964d0b160c48699adb38f71138d05b/setup.py\", line 40, in <module>\n",
      "  \u001b[31m   \u001b[0m     setuptools.setup()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/setuptools/__init__.py\", line 103, in setup\n",
      "  \u001b[31m   \u001b[0m     _install_setup_requires(attrs)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/setuptools/__init__.py\", line 74, in _install_setup_requires\n",
      "  \u001b[31m   \u001b[0m     dist.parse_config_files(ignore_option_errors=True)\n",
      "  \u001b[31m   \u001b[0m   File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/setuptools/dist.py\", line 633, in parse_config_files\n",
      "  \u001b[31m   \u001b[0m     self._finalize_requires()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/setuptools/dist.py\", line 368, in _finalize_requires\n",
      "  \u001b[31m   \u001b[0m     self._normalize_requires()\n",
      "  \u001b[31m   \u001b[0m   File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/setuptools/dist.py\", line 383, in _normalize_requires\n",
      "  \u001b[31m   \u001b[0m     self.install_requires = list(map(str, _reqs.parse(install_requires)))\n",
      "  \u001b[31m   \u001b[0m                             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  \u001b[31m   \u001b[0m   File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/setuptools/_vendor/packaging/requirements.py\", line 37, in __init__\n",
      "  \u001b[31m   \u001b[0m     raise InvalidRequirement(str(e)) from e\n",
      "  \u001b[31m   \u001b[0m setuptools.extern.packaging.requirements.InvalidRequirement: Expected end or semicolon (after name and no valid version specifier)\n",
      "  \u001b[31m   \u001b[0m     python_version>\"3.7\"\n",
      "  \u001b[31m   \u001b[0m                   ^\n",
      "  \u001b[31m   \u001b[0m \u001b[31m[end of output]\u001b[0m\n",
      "  \n",
      "  \u001b[1;35mnote\u001b[0m: This error originates from a subprocess, and is likely not a problem with pip.\n",
      "\u001b[1;31merror\u001b[0m: \u001b[1mmetadata-generation-failed\u001b[0m\n",
      "\n",
      "\u001b[31m×\u001b[0m Encountered error while generating package metadata.\n",
      "\u001b[31m╰─>\u001b[0m See above for output.\n",
      "\n",
      "\u001b[1;35mnote\u001b[0m: This is an issue with the package mentioned above, not pip.\n",
      "\u001b[1;36mhint\u001b[0m: See above for details.\n",
      "\u001b[?25hNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow-gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "88e4fdbe-998e-4d74-be1d-3de61cffc580",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-06-26 20:32:12.986019: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986090: W tensorflow/core/framework/local_rendezvous.cc:404] Local rendezvous is aborting with status: UNKNOWN: JIT compilation failed.\n",
      "\t [[{{function_node __inference_one_step_on_data_10726}}{{node adam/Pow_13}}]]\n",
      "2024-06-26 20:32:12.986115: I tensorflow/core/framework/local_rendezvous.cc:426] Local rendezvous send item cancelled. Key hash: 8450978442353663687\n",
      "2024-06-26 20:32:12.986145: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986178: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986209: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986229: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986248: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986268: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986286: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986306: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986325: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986345: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986363: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986382: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986401: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986420: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986439: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986458: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n",
      "2024-06-26 20:32:12.986477: W tensorflow/core/framework/op_kernel.cc:1827] UNKNOWN: JIT compilation failed.\n"
     ]
    },
    {
     "ename": "UnknownError",
     "evalue": "Graph execution error:\n\nDetected at node adam/Pow_13 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_173824/35520191.py\", line 30, in <module>\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 314, in fit\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 117, in one_step_on_iterator\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 104, in one_step_on_data\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 69, in train_step\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 351, in apply\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 405, in _backend_apply_gradients\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 119, in _backend_update_step\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 135, in _distributed_tf_update_step\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 132, in apply_grad_to_update_var\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/optimizers/adam.py\", line 123, in update_step\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/ops/numpy.py\", line 5603, in power\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\", line 2252, in power\n\nJIT compilation failed.\n\t [[{{node adam/Pow_13}}]] [Op:__inference_one_step_on_iterator_10799]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mUnknownError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m model2\u001b[38;5;241m.\u001b[39mcompile(optimizer\u001b[38;5;241m=\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m), loss\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbinary_crossentropy\u001b[39m\u001b[38;5;124m'\u001b[39m, metrics\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124maccuracy\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_train_pad\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalidation_split\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0.2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;66;03m# Evaluate the model on the test set\u001b[39;00m\n\u001b[1;32m     33\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m model2\u001b[38;5;241m.\u001b[39mevaluate(X_test_pad, y_test)\n",
      "File \u001b[0;32m~/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/reu/lib/python3.11/site-packages/tensorflow/python/eager/execute.py:53\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m     52\u001b[0m   ctx\u001b[38;5;241m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 53\u001b[0m   tensors \u001b[38;5;241m=\u001b[39m pywrap_tfe\u001b[38;5;241m.\u001b[39mTFE_Py_Execute(ctx\u001b[38;5;241m.\u001b[39m_handle, device_name, op_name,\n\u001b[1;32m     54\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m core\u001b[38;5;241m.\u001b[39m_NotOkStatusException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m     56\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[0;31mUnknownError\u001b[0m: Graph execution error:\n\nDetected at node adam/Pow_13 defined at (most recent call last):\n  File \"<frozen runpy>\", line 198, in _run_module_as_main\n\n  File \"<frozen runpy>\", line 88, in _run_code\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel_launcher.py\", line 18, in <module>\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/kernelapp.py\", line 739, in start\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/tornado/platform/asyncio.py\", line 195, in start\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/asyncio/base_events.py\", line 608, in run_forever\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/asyncio/base_events.py\", line 1936, in _run_once\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/asyncio/events.py\", line 84, in _run\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/IPython/core/async_helpers.py\", line 129, in _pseudo_sync_runner\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n\n  File \"/tmp/ipykernel_173824/35520191.py\", line 30, in <module>\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py\", line 117, in error_handler\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 314, in fit\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 117, in one_step_on_iterator\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 104, in one_step_on_data\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/trainer.py\", line 69, in train_step\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 282, in apply_gradients\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 351, in apply\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/optimizers/base_optimizer.py\", line 405, in _backend_apply_gradients\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 119, in _backend_update_step\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 135, in _distributed_tf_update_step\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/optimizer.py\", line 132, in apply_grad_to_update_var\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/optimizers/adam.py\", line 123, in update_step\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/ops/numpy.py\", line 5603, in power\n\n  File \"/home/claney/anaconda3/envs/reu/lib/python3.11/site-packages/keras/src/backend/tensorflow/numpy.py\", line 2252, in power\n\nJIT compilation failed.\n\t [[{{node adam/Pow_13}}]] [Op:__inference_one_step_on_iterator_10799]"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from keras.layers import Embedding\n",
    "# Tokenize the text descriptions\n",
    "tokenizer = Tokenizer(num_words=5000)\n",
    "tokenizer.fit_on_texts(X_train)\n",
    "X_train_seq = tokenizer.texts_to_sequences(X_train)\n",
    "X_test_seq = tokenizer.texts_to_sequences(X_test)\n",
    "\n",
    "# Pad the sequences to ensure uniform input size\n",
    "max_sequence_length = 100\n",
    "X_train_pad = pad_sequences(X_train_seq, maxlen=max_sequence_length)\n",
    "X_test_pad = pad_sequences(X_test_seq, maxlen=max_sequence_length)\n",
    "\n",
    "# Build the Sequential model\n",
    "model2 = Sequential()\n",
    "model2.add(Embedding(input_dim=5000, output_dim=64))\n",
    "model2.add(LSTM(64, return_sequences=True))\n",
    "model2.add(Dropout(0.5))\n",
    "model2.add(LSTM(32))\n",
    "model2.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model2.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model2.fit(X_train_pad, y_train, epochs=10, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss, accuracy = model2.evaluate(X_test_pad, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f29d17a-9ea1-4211-9c6c-de750046ff3e",
   "metadata": {},
   "source": [
    "# BERT trasformer model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8f7e261-4cb9-46b2-83df-055abcd66970",
   "metadata": {},
   "outputs": [],
   "source": [
    "#gave thiis error\n",
    "#RuntimeError: Failed to import transformers.models.bert.modeling_tf_bert because of the following error (look up to see its traceback):\n",
    "#Your currently installed version of Keras is Keras 3, but this is not yet supported in Transformers. Please install the backwards-compatible tf-keras package with `pip install tf-keras`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "acd3d55c-e138-4a00-a15f-c3900f0513b4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tf-keras\n",
      "  Downloading tf_keras-2.16.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Requirement already satisfied: tensorflow<2.17,>=2.16 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tf-keras) (2.16.1)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.0)\n",
      "Requirement already satisfied: packaging in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (24.1)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.25.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.32.3)\n",
      "Requirement already satisfied: setuptools in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (0.37.0)\n",
      "Requirement already satisfied: numpy<2.0.0,>=1.23.5 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow<2.17,>=2.16->tf-keras) (1.26.4)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow<2.17,>=2.16->tf-keras) (0.43.0)\n",
      "Requirement already satisfied: rich in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from requests<3,>=2.21.0->tensorflow<2.17,>=2.16->tf-keras) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow<2.17,>=2.16->tf-keras) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow<2.17,>=2.16->tf-keras) (0.1.2)\n",
      "Downloading tf_keras-2.16.0-py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tf-keras\n",
      "Successfully installed tf-keras-2.16.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tf-keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ba466230-5cac-4f37-8752-83efa35f43fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x7fd0fc331910>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[29], line 55\u001b[0m\n\u001b[1;32m     37\u001b[0m var_name \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(\n\u001b[1;32m     38\u001b[0m     learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.001\u001b[39m,\n\u001b[1;32m     39\u001b[0m     beta_1\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     52\u001b[0m     name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124madam\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     53\u001b[0m )\n\u001b[1;32m     54\u001b[0m loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 55\u001b[0m \u001b[43mmodel3\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvar_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     58\u001b[0m model3\u001b[38;5;241m.\u001b[39mfit(train_dataset, epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m3\u001b[39m, validation_data\u001b[38;5;241m=\u001b[39mtest_dataset)\n",
      "File \u001b[0;32m~/anaconda3/envs/reu/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:1563\u001b[0m, in \u001b[0;36mTFPreTrainedModel.compile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;66;03m# This argument got renamed, we need to support both versions\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps_per_execution\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parent_args:\n\u001b[0;32m-> 1563\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweighted_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweighted_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_eagerly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_eagerly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m   1575\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m   1576\u001b[0m         loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1583\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/reu/lib/python3.11/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/reu/lib/python3.11/site-packages/tf_keras/src/optimizers/__init__.py:335\u001b[0m, in \u001b[0;36mget\u001b[0;34m(identifier, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get(\n\u001b[1;32m    331\u001b[0m         config,\n\u001b[1;32m    332\u001b[0m         use_legacy_optimizer\u001b[38;5;241m=\u001b[39muse_legacy_optimizer,\n\u001b[1;32m    333\u001b[0m     )\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret optimizer identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x7fd0fc331910>"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer, TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# Assuming you have your data prepared as X_train, y_train, X_test, y_test\n",
    "\n",
    "# Load pre-trained BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model3 = TFBertForSequenceClassification.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Tokenize inputs\n",
    "def tokenize_text(text):\n",
    "    return tokenizer.encode_plus(\n",
    "        text,\n",
    "        add_special_tokens=True,\n",
    "        max_length=128,\n",
    "        padding='max_length',\n",
    "        return_attention_mask=True,\n",
    "        truncation=True\n",
    "    )\n",
    "\n",
    "# Tokenize and encode inputs\n",
    "X_train_tokens = [tokenize_text(text) for text in X_train]\n",
    "X_test_tokens = [tokenize_text(text) for text in X_test]\n",
    "\n",
    "# Convert tokens to TensorFlow Dataset\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {key: tf.constant([token[key] for token in X_train_tokens]) for key in X_train_tokens[0].keys()},\n",
    "    tf.constant(y_train)\n",
    ")).shuffle(100).batch(32)\n",
    "\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((\n",
    "    {key: tf.constant([token[key] for token in X_test_tokens]) for key in X_test_tokens[0].keys()},\n",
    "    tf.constant(y_test)\n",
    ")).batch(32)\n",
    "\n",
    "# Fine-tune BERT model\n",
    "var_name = tf.keras.optimizers.Adam(\n",
    "    learning_rate=0.001,\n",
    "    beta_1=0.9,\n",
    "    beta_2=0.999,\n",
    "    epsilon=1e-07,\n",
    "    amsgrad=False,\n",
    "    weight_decay=None,\n",
    "    clipnorm=None,\n",
    "    clipvalue=None,\n",
    "    global_clipnorm=None,\n",
    "    use_ema=False,\n",
    "    ema_momentum=0.99,\n",
    "    ema_overwrite_frequency=None,\n",
    "    loss_scale_factor=None,\n",
    "    gradient_accumulation_steps=None,\n",
    "    name='adam',\n",
    ")\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model3.compile(optimizer=var_name, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model3.fit(train_dataset, epochs=3, validation_data=test_dataset)\n",
    "\n",
    "# Evaluate the model\n",
    "results = model3.evaluate(test_dataset)\n",
    "print(f'Loss: {results[0]}, Accuracy: {results[1]}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e5da0e5-8140-40ec-87ad-cc5c2f75640f",
   "metadata": {},
   "source": [
    "# UGhHH im trying anything at this point"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9abf78c7-b2dd-4f48-b5dd-1bd3ac2df36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (4.41.2)\n",
      "Requirement already satisfied: tensorflow in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (2.16.1)\n",
      "Requirement already satisfied: filelock in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from transformers) (3.15.4)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from transformers) (0.23.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from transformers) (1.26.4)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from transformers) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from transformers) (2024.5.15)\n",
      "Requirement already satisfied: requests in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.20,>=0.19 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from transformers) (0.19.1)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from transformers) (0.4.3)\n",
      "Requirement already satisfied: tqdm>=4.27 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from transformers) (4.66.4)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=23.5.26 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (0.5.4)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: h5py>=3.10.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: ml-dtypes~=0.3.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (0.3.2)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (3.3.0)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (4.25.3)\n",
      "Requirement already satisfied: setuptools in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (2.4.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (4.12.2)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (1.64.1)\n",
      "Requirement already satisfied: tensorboard<2.17,>=2.16 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (2.16.2)\n",
      "Requirement already satisfied: keras>=3.0.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (3.3.3)\n",
      "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorflow) (0.37.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.23.0->transformers) (2024.6.0)\n",
      "Requirement already satisfied: rich in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (13.7.1)\n",
      "Requirement already satisfied: namex in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from keras>=3.0.0->tensorflow) (0.11.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from requests->transformers) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from requests->transformers) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from requests->transformers) (2024.6.2)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.6)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from tensorboard<2.17,>=2.16->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from werkzeug>=1.0.1->tensorboard<2.17,>=2.16->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from rich->keras>=3.0.0->tensorflow) (2.18.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/claney/anaconda3/envs/reu/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.0.0->tensorflow) (0.1.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers tensorflow\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6fe5953b-fb62-45e5-bce7-ba9108775497",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from transformers import BertTokenizer\n",
    "\n",
    "# Sample data (replace with your own bug reports and labels)\n",
    "\n",
    "\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "max_len = 20  # Max length of your sequences\n",
    "\n",
    "# Tokenize and encode sequences\n",
    "encoded_data = tokenizer(\n",
    "    df['full_text_data'].tolist(),\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    "    max_length=max_len,\n",
    "    return_tensors='tf'\n",
    ")\n",
    "\n",
    "labels = np.array(df['isDuplicate'])\n",
    "\n",
    "# Convert tensors to numpy arrays\n",
    "input_ids_np = np.array(encoded_data['input_ids'])\n",
    "attention_mask_np = np.array(encoded_data['attention_mask'])\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train_ids, X_test_ids, X_train_masks, X_test_masks, y_train, y_test = train_test_split(\n",
    "    input_ids_np,\n",
    "    attention_mask_np,\n",
    "    labels,\n",
    "    test_size=0.2,\n",
    "    random_state=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e2ae46ec-f53e-4bc1-bc6f-42194431956e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "All PyTorch model weights were used when initializing TFBertForSequenceClassification.\n",
      "\n",
      "Some weights or buffers of the TF 2.0 model TFBertForSequenceClassification were not initialized from the PyTorch model and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x7fd1247a6b10>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[40], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39moptimizers\u001b[38;5;241m.\u001b[39mAdam(learning_rate\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2e-5\u001b[39m)\n\u001b[1;32m      9\u001b[0m loss \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mkeras\u001b[38;5;241m.\u001b[39mlosses\u001b[38;5;241m.\u001b[39mSparseCategoricalCrossentropy(from_logits\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43maccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;66;03m# Train the model\u001b[39;00m\n\u001b[1;32m     13\u001b[0m history \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mfit(\n\u001b[1;32m     14\u001b[0m     X_train,\n\u001b[1;32m     15\u001b[0m     y_train,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     validation_data\u001b[38;5;241m=\u001b[39m(X_test, y_test)\n\u001b[1;32m     19\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/reu/lib/python3.11/site-packages/transformers/modeling_tf_utils.py:1563\u001b[0m, in \u001b[0;36mTFPreTrainedModel.compile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, weighted_metrics, run_eagerly, steps_per_execution, **kwargs)\u001b[0m\n\u001b[1;32m   1561\u001b[0m \u001b[38;5;66;03m# This argument got renamed, we need to support both versions\u001b[39;00m\n\u001b[1;32m   1562\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msteps_per_execution\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m parent_args:\n\u001b[0;32m-> 1563\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[43m        \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1565\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1566\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1567\u001b[0m \u001b[43m        \u001b[49m\u001b[43mloss_weights\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mloss_weights\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1568\u001b[0m \u001b[43m        \u001b[49m\u001b[43mweighted_metrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweighted_metrics\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1569\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrun_eagerly\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_eagerly\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1570\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_execution\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msteps_per_execution\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1571\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1572\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1573\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   1574\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39mcompile(\n\u001b[1;32m   1575\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[1;32m   1576\u001b[0m         loss\u001b[38;5;241m=\u001b[39mloss,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1582\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   1583\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/reu/lib/python3.11/site-packages/tf_keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/reu/lib/python3.11/site-packages/tf_keras/src/optimizers/__init__.py:335\u001b[0m, in \u001b[0;36mget\u001b[0;34m(identifier, **kwargs)\u001b[0m\n\u001b[1;32m    330\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m get(\n\u001b[1;32m    331\u001b[0m         config,\n\u001b[1;32m    332\u001b[0m         use_legacy_optimizer\u001b[38;5;241m=\u001b[39muse_legacy_optimizer,\n\u001b[1;32m    333\u001b[0m     )\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    336\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCould not interpret optimizer identifier: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00midentifier\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    337\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: Could not interpret optimizer identifier: <keras.src.optimizers.adam.Adam object at 0x7fd1247a6b10>"
     ]
    }
   ],
   "source": [
    "from transformers import TFBertForSequenceClassification\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load pre-trained BERT model\n",
    "model = TFBertForSequenceClassification.from_pretrained('bert-base-uncased', num_labels=2)\n",
    "\n",
    "# Compile the model\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=2e-5)\n",
    "loss = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
    "model.compile(optimizer=optimizer, loss=loss, metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train,\n",
    "    y_train,\n",
    "    epochs=3,\n",
    "    batch_size=32,\n",
    "    validation_data=(X_test, y_test)\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e117309-dd83-459c-a9c9-9f610bdbc255",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
