{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_3432728/4273510478.py:36: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['full_text_data'] = df['Description'].fillna('') + ' ' + df['Title'].fillna('')\n",
      "/tmp/ipykernel_3432728/4273510478.py:41: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['isDuplicate'] = df['Duplicated_issue'].apply(lambda x: is_duplicate(x))\n",
      "/tmp/ipykernel_3432728/4273510478.py:47: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['tokenized_text'] = df['full_text_data'].apply(tokenize)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.85      0.84     14032\n",
      "           1       0.22      0.20      0.21      2999\n",
      "\n",
      "    accuracy                           0.74     17031\n",
      "   macro avg       0.53      0.52      0.53     17031\n",
      "weighted avg       0.73      0.74      0.73     17031\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import scipy.stats as st\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "import requests\n",
    "import xml.etree.ElementTree as ET\n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "# Load and preprocess the data\n",
    "csv_file = '/home/abarovic/laneyREUTest/eclipse_platform.csv'\n",
    "full_df = pd.read_csv(csv_file)\n",
    "\n",
    "full_df.fillna(0, inplace=True)\n",
    "length = len(full_df)\n",
    "split_index = int(.8 * length)\n",
    "df = full_df.iloc[:split_index]  # Training set\n",
    "\n",
    "df['full_text_data'] = df['Description'].fillna('') + ' ' + df['Title'].fillna('')\n",
    "\n",
    "def is_duplicate(val):\n",
    "    return 1 if val != 0.0 else 0\n",
    "\n",
    "df['isDuplicate'] = df['Duplicated_issue'].apply(lambda x: is_duplicate(x))\n",
    "\n",
    "# Tokenize the text data\n",
    "def tokenize(text):\n",
    "    return word_tokenize(text.lower())\n",
    "\n",
    "df['tokenized_text'] = df['full_text_data'].apply(tokenize)\n",
    "\n",
    "# Split the data\n",
    "X = df['tokenized_text']  # Tokenized input features\n",
    "y = df['isDuplicate']     # Target variable\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42, stratify=y)\n",
    "\n",
    "# Train a Word2Vec model\n",
    "w2v_model = Word2Vec(sentences=X_train, vector_size=100, window=5, min_count=1, workers=4, sg=0)\n",
    "\n",
    "# Helper function to convert a list of words into a single vector\n",
    "def vectorize_text(tokens, model):\n",
    "    word_vectors = [model.wv[word] for word in tokens if word in model.wv]\n",
    "    if len(word_vectors) > 0:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(model.vector_size)\n",
    "\n",
    "# Vectorize the training and testing data\n",
    "X_train_vectors = np.array([vectorize_text(tokens, w2v_model) for tokens in X_train])\n",
    "X_test_vectors = np.array([vectorize_text(tokens, w2v_model) for tokens in X_test])\n",
    "\n",
    "# Fit the Gaussian Naive Bayes model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train_vectors, y_train)\n",
    "\n",
    "# Predict using the validation data\n",
    "y_pred = gnb.predict(X_test_vectors)\n",
    "\n",
    "# Calculate and print the classification report\n",
    "report = classification_report(y_test, y_pred)\n",
    "print(report)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "laney_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
